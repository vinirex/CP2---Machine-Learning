{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51875ea",
   "metadata": {},
   "source": [
    "# Análise de Regressão Logística — Comentada\n",
    "\n",
    "Notebook revisado e comentado para a prova de Regressão Logística.\n",
    "\n",
    "Este notebook contém duas partes:\n",
    "- **Parte A**: Análise exploratória, padronização, GridSearchCV (L1/L2) e avaliação final.\n",
    "- **Parte B**: Implementação alternativa que treina uma 'regressão logística' minimizando **MSE/RMSE** em vez de log-loss; comparações e discussões.\n",
    "\n",
    "O código está comentado conforme os requisitos do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6faf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay, classification_report)\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Carregar o dataset (voice.csv) ===\n",
    "# URL fornecida no enunciado\n",
    "url = 'https://raw.githubusercontent.com/primaryobjects/voice-gender/master/voice.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Visualizar primeiras linhas e info básica\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())\n",
    "display(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d252c",
   "metadata": {},
   "source": [
    "## Parte A — Análise Exploratória (EDA)\n",
    "\n",
    "1. Verificar balanceamento, distribuições, correlações, e necessidade de padronização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc192a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Balanceamento do alvo\n",
    "counts = df['label'].value_counts()\n",
    "print('Contagem por classe:\\n', counts)\n",
    "print('\\nProporção de positivos (male):', (df['label']=='male').mean())\n",
    "\n",
    "# 2) Estatísticas descritivas das features (excluindo label)\n",
    "X_df = df.drop(columns=['label'])\n",
    "display(X_df.describe().T)\n",
    "\n",
    "# 3) Histogramas de algumas features exemplares (subamostra para visual)\n",
    "features = X_df.columns.tolist()\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, col in enumerate(features[:6]):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    sns.histplot(X_df[col], kde=True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) Matriz de correlação\n",
    "plt.figure(figsize=(10,8))\n",
    "corr = X_df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlação (features)')\n",
    "plt.show()\n",
    "\n",
    "# Observação sobre escalas\n",
    "print('\\nMínimos e máximos mostram escalas diferentes — por isso padronização é necessária para regularização e modelos baseados em gradiente.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c773b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Preparação: X, y, train-test split e padronização ===\n",
    "X = X_df.values\n",
    "y = (df['label'] == 'male').astype(int).values\n",
    "\n",
    "# Stratified split para manter proporções de classes\n",
    "RND = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RND, stratify=y)\n",
    "\n",
    "# Padronização com StandardScaler (fit no treino somente)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "print('Shapes:', X_train_s.shape, X_test_s.shape)\n",
    "print('Distribuições treino:', np.bincount(y_train), 'teste:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785729a",
   "metadata": {},
   "source": [
    "### GridSearchCV (L1 vs L2) — Parte A\n",
    "Configuração de GridSearchCV com `StratifiedKFold` (k=5) testando penalizações L1/L2 e valores de C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf203525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param grid e modelo base\n",
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\n",
    "lr = LogisticRegression(solver='saga', max_iter=5000, random_state=RND)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RND)\n",
    "\n",
    "grid = GridSearchCV(lr, param_grid, scoring='accuracy', cv=cv, n_jobs=-1, verbose=0)\n",
    "grid.fit(X_train_s, y_train)\n",
    "\n",
    "print('Melhor Score (CV):', grid.best_score_)\n",
    "print('Melhores Parâmetros:', grid.best_params_)\n",
    "\n",
    "# Reajuste com melhores parâmetros e avaliar no teste\n",
    "best = grid.best_estimator_\n",
    "best.fit(X_train_s, y_train)\n",
    "y_pred = best.predict(X_test_s)\n",
    "y_proba = best.predict_proba(X_test_s)[:,1]\n",
    "\n",
    "print('\\nRelatório no conjunto de teste:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['female','male']).plot(cmap='Blues')\n",
    "plt.title('Matriz de Confusão - GridSearchCV (melhor modelo)')\n",
    "plt.show()\n",
    "\n",
    "print('AUC ROC (teste):', roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744f7b3",
   "metadata": {},
   "source": [
    "## Parte B — Treinamento minimizando MSE/RMSE (em vez de Log-Loss)\n",
    "\n",
    "Implementamos um modelo manual que mantém a função sigmóide para probabilidades, mas **minimiza MSE** (equivalente monotonicamente ao RMSE). Usamos gradiente analítico e `scipy.optimize.minimize` (L-BFGS-B) para encontrar os coeficientes que minimizam MSE — e reportamos RMSE para comparação.\n",
    "\n",
    "A seguir há: implementação, treinamento, avaliação e comparação com sklearn (log-loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d68640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Implementação do modelo que minimiza MSE (reportamos RMSE) ---\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# Objetivo: MSE (mais estável numericamente que RMSE para gradiente), mas retornaremos RMSE para leitura.\n",
    "def mse_loss(theta, X, y):\n",
    "    X_ = np.c_[np.ones(X.shape[0]), X]\n",
    "    p = sigmoid(X_ @ theta)\n",
    "    return np.mean((y - p)**2)\n",
    "\n",
    "def mse_grad(theta, X, y):\n",
    "    X_ = np.c_[np.ones(X.shape[0]), X]\n",
    "    z = X_ @ theta\n",
    "    p = sigmoid(z)\n",
    "    n = X_.shape[0]\n",
    "    # grad MSE = ( -2/n ) * X_.T @ ( (y - p) * p * (1-p) )\n",
    "    residual = (y - p)\n",
    "    dp_dtheta_factor = p * (1 - p)\n",
    "    inner = -2.0 * residual * dp_dtheta_factor\n",
    "    grad = (X_.T @ inner) / n\n",
    "    return grad\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def fit_mse_lbfgs(X, y):\n",
    "    theta0 = np.zeros(X.shape[1] + 1)\n",
    "    # We minimize RMSE explicitly to match requested metric, but provide analytic jac via chain rule from MSE\n",
    "    res = minimize(lambda th, X, y: np.sqrt(mse_loss(th, X, y)), theta0, args=(X, y),\n",
    "                   method='L-BFGS-B',\n",
    "                   jac=lambda th, X, y: (mse_grad(th, X, y) / (2.0 * max(1e-12, np.sqrt(mse_loss(th, X, y))))),\n",
    "                   options={'maxiter':2000, 'ftol':1e-9})\n",
    "    return res\n",
    "\n",
    "# Treinamento usando X_train_s (padronizado)\n",
    "res_mse = fit_mse_lbfgs(X_train_s, y_train)\n",
    "theta_mse = res_mse.x\n",
    "print('Convergência:', res_mse.success, res_mse.message)\n",
    "print('RMSE (treino):', np.sqrt(mse_loss(theta_mse, X_train_s, y_train)))\n",
    "\n",
    "# Predição\n",
    "X_test_aug = np.c_[np.ones(X_test_s.shape[0]), X_test_s]\n",
    "y_proba_mse = sigmoid(X_test_aug @ theta_mse)\n",
    "y_pred_mse = (y_proba_mse >= 0.5).astype(int)\n",
    "\n",
    "# Métricas\n",
    "print('\\n=== Modelo MSE (reportando RMSE) ===')\n",
    "print(classification_report(y_test, y_pred_mse, digits=4))\n",
    "print('AUC ROC (teste):', roc_auc_score(y_test, y_proba_mse))\n",
    "cm_mse = confusion_matrix(y_test, y_pred_mse)\n",
    "ConfusionMatrixDisplay(cm_mse, display_labels=['female','male']).plot(cmap='Blues')\n",
    "plt.title('Matriz de Confusão - MSE-trained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafce331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Experimento: adicionar ruído e desbalancear o treino para evidenciar diferenças ===\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def add_label_noise(y, noise_ratio=0.2):\n",
    "    y_noisy = y.copy()\n",
    "    n_flip = int(len(y) * noise_ratio)\n",
    "    flip_idx = np.random.choice(len(y), n_flip, replace=False)\n",
    "    y_noisy[flip_idx] = 1 - y_noisy[flip_idx]\n",
    "    return y_noisy\n",
    "\n",
    "def make_imbalanced(X, y, minority_ratio=0.3):\n",
    "    idx_min = np.where(y == 1)[0]\n",
    "    idx_maj = np.where(y == 0)[0]\n",
    "    n_min_keep = max(1, int(len(idx_min) * minority_ratio))\n",
    "    keep_idx = np.concatenate([idx_maj, np.random.choice(idx_min, n_min_keep, replace=False)])\n",
    "    return X[keep_idx], y[keep_idx]\n",
    "\n",
    "# Criar versão ruidosa e desbalanceada do treino\n",
    "y_train_noisy = add_label_noise(y_train, noise_ratio=0.20)\n",
    "X_train_imb, y_train_imb = make_imbalanced(X_train_s, y_train_noisy, minority_ratio=0.3)\n",
    "print('Tamanho treino original:', len(y_train), 'pós-desbalanceamento:', len(y_train_imb))\n",
    "print('Proporção classe positiva (treino modificado):', y_train_imb.mean())\n",
    "\n",
    "# Treinar os dois modelos no treino modificado\n",
    "# 1) MSE-trained\n",
    "res_mse2 = fit_mse_lbfgs(X_train_imb, y_train_imb)\n",
    "theta_mse2 = res_mse2.x\n",
    "y_proba_mse2 = sigmoid(np.c_[np.ones(X_test_s.shape[0]), X_test_s] @ theta_mse2)\n",
    "y_pred_mse2 = (y_proba_mse2 >= 0.5).astype(int)\n",
    "\n",
    "# 2) sklearn logistic (log-loss)\n",
    "lr2 = LogisticRegression(solver='lbfgs', max_iter=5000, random_state=RND)\n",
    "lr2.fit(X_train_imb, y_train_imb)\n",
    "y_proba_skl2 = lr2.predict_proba(X_test_s)[:,1]\n",
    "y_pred_skl2 = lr2.predict(X_test_s)\n",
    "\n",
    "# Comparação de métricas\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print('\\n=== Após ruído/desbalanceamento ===')\n",
    "print('MSE-trained: ACC =', accuracy_score(y_test, y_pred_mse2), 'AUC =', roc_auc_score(y_test, y_proba_mse2))\n",
    "print('Log-loss (sklearn): ACC =', accuracy_score(y_test, y_pred_skl2), 'AUC =', roc_auc_score(y_test, y_proba_skl2))\n",
    "\n",
    "# Plots comparativos\n",
    "fpr_m, tpr_m, _ = roc_curve(y_test, y_proba_mse2)\n",
    "fpr_s, tpr_s, _ = roc_curve(y_test, y_proba_skl2)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_m, tpr_m, label=f'MSE-trained (AUC={roc_auc_score(y_test, y_proba_mse2):.3f})')\n",
    "plt.plot(fpr_s, tpr_s, label=f'Log-loss (AUC={roc_auc_score(y_test, y_proba_skl2):.3f})')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.legend()\n",
    "plt.title('ROC - Comparação após ruído/desbalanceamento')\n",
    "plt.show()\n",
    "\n",
    "# Histograma de probabilidades (calibração)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_proba_mse2[y_test==0], bins=30, alpha=0.6, label='neg')\n",
    "plt.hist(y_proba_mse2[y_test==1], bins=30, alpha=0.6, label='pos')\n",
    "plt.title('Probabilidades - MSE-trained')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_proba_skl2[y_test==0], bins=30, alpha=0.6, label='neg')\n",
    "plt.hist(y_proba_skl2[y_test==1], bins=30, alpha=0.6, label='pos')\n",
    "plt.title('Probabilidades - Log-loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e8641",
   "metadata": {},
   "source": [
    "## Discussão crítica (resposta do projeto)\n",
    "\n",
    "- **Por que RMSE é ruim para regressão logística?**\n",
    "  - Regressão logística modela probabilidades e a função de perda natural é a log-verossimilhança (log-loss).\n",
    "  - Log-loss penaliza fortemente previsões de alta confiança incorretas; RMSE não o faz de forma adequada.\n",
    "  - RMSE tende a 'puxar' probabilidades para valores centrais (ex.: 0.2–0.8) em vez de extremos (0 ou 1), degradando calibração e AUC em cenários ruidosos.\n",
    "\n",
    "- **Resultados observados:**\n",
    "  - Em dados limpos e separáveis, RMSE e Log-Loss podem levar a fronteiras de decisão próximas (portanto AC e AUC parecidas).\n",
    "  - Quando inserimos ruído e desbalanceamento, as diferenças tornam-se claras: o modelo treinado com log-loss mantém melhor separabilidade (AUC maior) e probabilidades mais extremas; o MSE-trained tende a produzir probabilidades mais centrais e AUC menor.\n",
    "\n",
    "- **Conclusão prática:**\n",
    "  - Use log-loss para classificação probabilística. Testar RMSE é válido academicamente, mas não recomendado para produção nem para interpretação de probabilidades.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
